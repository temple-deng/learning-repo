# 第2章 进程与线程

## 2.1 进程

### 2.1.1 进程模型

计算机上所有可运行的软件，通常也包括操作系统，被组织成若干顺序进程，简称进程。一个进程就是一个
正在执行程序的实例。    

一个程序如果运行了两次，那算作两个进程。    

### 2.1.2 进程的创建

4种主要事件会导致进程的创建：   

1. 系统初始化
2. 正在运行的程序执行了创建进程的系统调用
3. 用户请求创建一个新进程
4. 一个批处理作业的初始化   

最后一种创建进程的情形仅在大型机的批处理系统中应用。用户在这种系统中提交批处理作业。在操作系统认为有
资源可以运行另一个作业时，它创建一个新的进程，并运行其输入队列中的下一个作业。    

从技术上看，在所有的这些情形中，新进程都是由于一个已存在的进程执行了一个用于创建进程的系统调用而
创建的。这个进程可以是一个运行的用户进程、一个由键盘或鼠标启动的系统进程或者一个批处理管理进程。    

在 UNIX 中通常先使用 `fork` 调用创建一个一模一样的子进程，之后子进程再根据需要调用 `execve` 来修改
自己的内存映像，执行自己的任务。之所以安排两步建立进程，是为了在 fork 之后但在 execve 之前允许子进程处理其
文件描述符，这样就可以完成对标准输入文件、标准输出文件和标准错误文件的重定向。     

进程创建之后，父进程和子进程有各自不同的地址空间。如果其中某个进程在其地址空间中修改了一个子，这个修改
对其他进程而言是不可见的。某些 UNIX 的实现使程序正文在两者间共享，因为它不能被修改。或者，
子进程共享父进程的所有内存，但这种情况下内存通过**写时复制**共享，这意味着一旦两者之一想要修改部分内存，
则这块内存首先被明确地复制，以确保修改发生在私有内存区域。    

### 2.1.3 进程的终止

迟早某个进程会终止，通常由下列条件引起：   

1. 正常退出（自愿的）
2. 出错退出（自愿的）
3. 严重错误（非自愿）
4. 被其他进程杀死（非自愿）    

### 2.1.4 进程的层次结构

在某些系统中，当进程创建了另一个进程后，父进程和子进程就以某种形式继续保持关联。子进程自己可以
创建更多的进程，组成一个进程的层次结构。    

在 UNIX 中，进程和它的所有子进程及后裔共同组成一个进程组。当用户从键盘发出一个信号时，该信号被送给
当前与键盘有关的进程组中的所有成员。每个进程可以分别捕获该信号、忽略该信号或采取默认的动作，即被该信号
杀死。    

Windows 中没有进程层次的概念，所有的进程都是地位相同的。唯一类似进程层次的暗示是在创建进程的时候，
父进程得到一个特别的令牌（称为**句柄**），该句柄可以用来控制子进程，但是，它有权把这个令牌送给某个
其他进程。    

### 2.1.5 进程的状态

当一个进程在逻辑上不能继续运行时，它就会被阻塞，典型的例子是它在等待可以使用的输入。还有可能是这样的
情况：一个概念上能够运行的进程被迫停止，因为操作系统调度另一个进程占用了 CPU。这两种情况是完全不同的。
在第一种情况下，进程挂起是程序自身固有的原因。第二种情况则是系统技术上的原因引起的。   

因此，进程分别可能处于三种状态：   

1. 运行态（该时刻进程实际占用CPU）
2. 就绪态（可运行，但因为其他进程正在运行而暂时停止）
3. 阻塞态（除非某种外部事件发生，否则进程不能运行）    

### 2.1.6 进程的实现

为了实现进程模型，操作系统维护着一张表格，即**进程表**。每个进程占用一个进程表项。该表项包含了进程
状态的重要信息，包括程序计数器、堆栈指针、内存分配状况、所打开文件的状态、账号和调度信息，以及其他在进程
由运行态装换到就绪态或阻塞态时必须保存的信息，从而保证该进程随后能再次启动，就像从未被中断过一样。     

```
------------------------------------------
| 进程管理       |  存储管理    | 文件管理   |
-----------------------------------------
| 寄存器        |  正文段指针   | 根目录     |
| 程序计数器     |  数据段指针   | 工作目录   |
| 程序状态字     |  堆栈段指针   | 文件描述符 |
| 进程状态      |              | 用户ID    |
| 优先级        |             |  组 ID    |
| 调度参数      |              |          |
| 进程ID       |              |           |
| 父进程        |             |           |
| 进程组        |              |          |
| 信号          |             |           |
| 进程开始时间   |              |          |
| 使用的 CPU 时间 |            |           |
| 子进程的 CPU 时间 |           |          |
| 下次定时器时间  |             |          |
------------------------------------------
```    


### 2.1.7 多道程序设计模型

假设一个进程等待 I/O 操作的时间与其停留在内存中的时间的比为 p。当内存中同时有 n 个进程时，则所有
n 个进程都在等待 I/O 的概率是 p的 n次方。则 CPU 的利用率由下面的公式给出：    

CPU利用率 = 1 - p<sup>n</sup>      

## 2.2 线程

在传统操作系统中，每个进程有一个地址空间和一个控制线程。事实上，这几乎就是进程的定义。不过，经常存在
同一个地址空间中准并行运行多个控制线程的情形，这些线程就像分离的进程（共享地址空间除外）。    


### 2.2.1 线程的使用

需要多线程的第一个原因是，在许多应用中同时发生着多种活动。其中某些活动随着时间的推移会被阻塞。通过将
这些应用程序分解成可以准并行运行的多个顺序线程，程序设计模型会变简单（都多线程了还简单？）。    

第二个关于需要多线程的理由是，由于线程比进程更轻量级，所以它们比进程更容易也更快创建，也更容易撤销。
通常创建一个线程较创建一个进程快10~100倍。    

第三个理由是多线程如果是大量的计算和I/O 处理，会加快程序的执行速度。    

### 2.2.2 经典的线程模型

进程模型基于两种独立的概念：资源分组与处理。有时，将这两种概念分开会更好，这就引入了“线程”的概念。    

理解进程的一个角度是，用某种方案把相关的资源集中在一起。进程存放程序正文和数据以及其他资源的地址空间。
这些资源中包括打开的文件、子进程、即将发生的定时器、信号处理程序、账号信息等。把它们放到进程中可以更
容易管理。    

而进程拥有一个执行的线程。在线程中有一个程序计数器，用来记录接着要执行哪一条指令。线程拥有寄存器，用来保存
线程当前的工作变量。还拥有一个堆栈指针，用来记录执行历史，其实每一帧保存了一个已调用的但是还有从中返回的
过程。尽管线程必须在进程中执行，但是线程和进程是不同的概念，可以分别处理。进程用于把资源集中到一起，而
线程则是在 CPU 上被调度执行的实体。   

所有的线程都有完全一样的地址空间，这意味着它们也共享同样的全局变量。由于各个线程都可以访问进程地址空间中
的每一个内存地址，所有一个线程可以读、写甚至清除另一个线程的堆栈。除了共享地址空间之外，所有线程还共享
同一个打开文件集、子进程、定时器以及相关信号等。    

```
---------------------------------
| 每个进程中的内容 | 每个线程中的内容 |
---------------------------------
| 地址空间        | 程序计数器      |
| 全局变量        | 寄存器         |
| 打开文件        | 堆栈           |
| 子进程          | 状态          |
| 即将发生的定时器 |               |
| 信号与信号处理程序 |              |
| 账户信息         |              |
---------------------------------   
```    

奇怪为什么 PSW 不是每个线程中都有呢？    

和传统进程一样，线程可以处于若干种状态的任何一个：运行、阻塞、就绪或终止。     

在多线程的情况下，进程通常会从当前的单个线程开始。这个线程有能力通过调用一个库函数（如 thread_create）
创建新的线程。thread_create 的参数专门指定了新线程要运行的过程名。创建线程通常会返回一个线程标识符，该
标识符就是新线程的名字。     

当一个线程完成工作后，可以通过一个调用库过程（如thread_exit）退出。在某些线程系统中，通过调用一个过程，例如
thread_join，一个线程可以等待线程退出。这个过程阻塞调用知道那个线程退出。    

另一个常见的线程调用 thread_yield，它允许线程自动放弃 CPU 从而让另一个线程运行。这样的调用是很重要
的，因为不同与进程，线程无法利用时钟中断强制线程让出 CPU，所以设法使线程随着时间的推移自动交出 CPU，
以便让其他线程有机会运行，就变得非常重要。    

### 2.2.3 POSIX 线程

IEEE 定义了一个线程的标准，这个线程包叫做 pthread。这个标准定义了超过60个函数调用。    

所有 pthread 线程都有某些特性。每一个都含有一个标识符、一组寄存器（包括程序计数器）和一组存储在结构中
的属性。这些属性包括堆栈大小、调度参数和其他线程需要的项目。    

创建一个新线程使用 pthread_create，新线程的线程标识符作为函数值返回。   

线程完成工作后可以调用 pthread_exit 终止。   

使用 pthread_join 线程调用来等待别的特定线程的终止。而要等待线程的标识符作为一个参数给出。   

使用 pthread_yield 调用来让线程自身让出 CPU。   

pthread_attr\_init 建立关联一个线程的属性结构并初始化成默认值，这些值可以通过修改属性结构中的域值
来改变。   

pthread_attr\_destroy 删除一个线程的属性结构，释放它占用的内存。    

### 2.2.4 在用户空间中实现线程

在用户空间管理线程时，每个进程需要有其专用的**线程表**，用来跟踪该进程中的线程，这些表和内核中的进程
表类似，不过它仅仅记录各个线程的属性，如每个线程的程序计数器、堆栈指针、寄存器和状态等。    

在用户空间管理线程时，线程间切换调度都只是本地过程，这样的切换要比陷入内核可能要块一个数量级，因为不需要
陷入内核，不需要上下午切换，不需要对内存高速缓存进行刷新（那说明这些操作是进程切换需要的）。     

在用户空间实现线程的缺点有：如何实现阻塞系统调用，因为阻塞系统调用会阻塞整个进程，其他的线程无法获得服务，
第二点是缺页中断问题，另外就是调度问题，如果一个运行中的线程迟迟不肯放弃 CPU，则其他线程无法获得服务。    

## 2.3 进程间通信

进程间通信需要考虑以下的三个问题：第一个就是一个进程如何把信息传递给另一个。第二个问题是确保两个
或更多的进程在关键活动中不会出现交叉。第三个是正确的顺序。    

### 2.3.1 竞争条件

在一些系统中，协作的进程可能共享一些彼此都能读写的公用存储区。这个公用存储区可能在内存中，也可能是一个
共享文件。类似这样的情况，即两个或多个进程读写某些共享数据，而最后的结果取决于进程运行的精确时序，
称为**竞争条件**。   

这里比较一下死锁，资源死锁通常是两个进程对一些资源的占用导致两个进程都阻塞起来，谁都不愿意释放已经占有
的资源，进而两者都无法继续运行，而死锁是两个进程对一些共享数据的读写取决于两者之间准备的执行顺序，而
顺序的错乱导致另一方获取到了错误的数据，进而引发进程的执行与预期的行为不一致。    

### 2.3.2 临界区

要避免竞争条件，关键是找出某种途径来避免多个进程同时读写共享的数据，就需要**互斥**，即以某种手段确保当一个进程在使用
共享的数据时，其他的进程不能做同样的操作。其实相当于把共享的数据锁住吧，其他的进程要是发现数据被加了
锁就阻塞，等待数据解锁后再进行操作。     

我们把对共享内存进行访问的程序片段称为**临界区域**或**临界区**。如果我们能适当安排，使得两个进程不可能
同时处于临界区中，就能够避免竞争条件。      

### 2.3. 忙等待的互斥

本节将讨论几种实现互斥的方案。在这些方案中，当一个进程在临界区中更新共享内存时，其他进程将不会进入临界区，
也不会带来任何麻烦。    

+ **屏蔽中断**     

在单处理器系统中，最简单的方法是使每个进程进入临界区后立即屏蔽所有中断，并且在离开时再打开中断。屏蔽中断
后，时钟中断也被屏蔽。CPU只有在发生时钟中断或其他中断时才会进行进程切换，这样，在屏蔽中断之后 CPU 将
不会被切换到其他进程。    

缺点很明显，如果进程屏蔽中断后不再打开中断，那么它就可以永远占据 CPU，整个系统就出问题了，而且这种情形
只适合单 CPU 的系统中，如果是多个 CPU 则其他未屏蔽中断的 CPU 还是可以访问临界数据的。    

+ **锁变量**     

这种方法是设想有一个共享锁变量，其初始值为0。当一个进程想要进入临界区时先访问这把锁，如果值为0就将其
设置为1并进入临界区（注意这个顺序很重要，如果我们先进入临界区再设置锁变量，还是可能导致竞争条件）。
若锁的值已经为1，则该进程将等待直到其值变为0。    

但是很明显这把锁也是一个共享变量，其本身就会导致竞争条件，所以这种方法其实也是有问题的。    

+ **严格轮换法**    

略。     

+ **Peterson 解法**     

```c
#define FALSE 0
#define TRUE 1
#define N 2

int turn;
int interested[N];

void enter_region(int process) {
  int other;

  other = 1 - process;
  interested[process] = TRUE;
  turn = process;
  while(turn == process && interested[other] == TRUE);
}

void leave_region(int process) {
  interested[process] = FALSE;
}
```    

一开始，没有进程处于临界区，进程0调用 `enter_region` 想要进入，这时进程1不想进入，因此`enter_region`
很快返回，于是进程0成功进入临界区，之后进程1想要就让临界区，调用 `enter_region` 但是被循环阻塞了，
知道进程0调用 `leave_region` 离开临界区后，进程1才能进入。    

现在考虑同时调用 `enter_region` 的情况，只有后保存到 `turn` 变量中的进程号有效，但是先保存进去的进程
反而可以进入临界区。    

+ **TSL 指令**    

上面两种是软件的方案，这种是硬件支持的方案，在现在的计算机中都有这样一条命令：`TSL RX,LOCK`，称为
**测试并加锁**（test and set lock），它将一个内存字lock 读取寄存器 RX 中，然后在该内存地址上存
一个非0值，读字和写字操作保证是不可分割的，即该指令结束之前其他处理器均不允许访问该内存字。执行 TSL 
指令的 CPU 将锁住内存总线。    

这里的话，任意的进程都可以利用 TSL 指令将 lock 设为1来进入临界区，而如果有同时想要进入临界区的进程，
它调用 TSL 指令读到 RX 中的lock 就是 1，那么就不能进入临界区。在操作结束后，进程用一条普通的 move
指令将 lock 值归为0。      

一个可替代 TSL 的指令是 XCHG，它原子性地交换了两个位置的内容，本质上与 TSL 是一致的。    

其实这个方法就可以看出，锁住内存总线来读写锁变量的值是一种很完美的方法。     

### 2.3.4 睡眠与唤醒

前面介绍的几种解法都有忙等待的问题，即进程在检查能否进入临界区时发现无法进入后，就开始执行循环直到
能进入，那这样很明显会浪费一个时间片的 CPU。而且还有**优先级反转问题**的出现。    

现在我们考察几条进程间通信原语，它们在无法进入临界区时将阻塞，而不是忙等待。最简单的是 `sleep` 和 `wakeup`。
`sleep` 是一个将引起调用进程阻塞的系统调用，即被挂起，直到另一个进程将其唤醒。`wakeup` 有一个参数，即
要被唤醒的进程（这有个问题啊，那必须是两个相关的进程才能用这两个原语吧，要是没关系的一个睡着了，另一个又
不知道其他进程的存在，怎么叫醒他呢）。 


不过单单用这两个原语的话会遇到生产者-消费者问题。    

### 2.3.5 信号量

信号量使用一个整型变量来累积唤醒次数，供以后使用，一个信号量的取值可以为0（表示没有保存下来的唤醒操作）
或者为正直（表示有一个或多个唤醒操作）。    

Dijkstra 建立设立两种操作：**down**和**up**（分别为一般化后的 sleep 和 wakeup）。对一信号量
执行 down 操作，则是检查其值是否为大于0。如果大于0，则将其值减1。如果等于0，则进程睡眠。检查数值、
修改变量值和进程睡眠均作为单一的、不可分割的原子操作完成。也就是说可以使用 TSL 指令来操作信号量。    

up 操作对信号量加1，如果一个或多个进程在该信号量上睡眠，无法完成一个先前的 down 操作（这是什么现象？
是进程都睡眠了以后又来一个 down 操作？但是没有说信号量在变为0之后还能往下减啊），则由系统选择其中的一个并允许该进程完成其 down 操作。于是，对一个
有进程在其上睡眠的信号量执行一次 up 操作之后，该信号量的值仍旧是0，但在其上的睡眠进程少了一个（那话说
这个进程到底是醒了没啊，完全看不懂啊）     

### 2.3.6 互斥量

互斥量是信号量的一个简化版本，互斥量是一个可以处于两态之一的变量：解锁和加锁。这样，只需要一个二进制位表示它。    

### 2.3.8 消息传递

与信号量有关的一个问题是，这个机制是设计用来解决公共内存的一个多个 CPU 上的互斥问题的。通过将信号量放在
共享内存中并用 TSL 或 XCHG 指令来保护它们，可以避免竞争。如果一个分布式系统具有多个 CPU，并且每个 CPU
都有自己的私有内存，它们通过一个局域网相连，那么这些原语将失效。话说，这难道不是 RPC 的范围了么。    

这时需要使用的方法是**消息传递**，这种进程间通信的方法使用两条原语send 和receive，它们像信号量，
是系统调用。     

### 2.3.9 屏障

最后一个同步机制是准备用于进程组而不是用于双进程的生产者-消费者情形的。在有些应用中划分了若干阶段，并且
规定，除非所有进程都就绪准备着手下一个阶段，否则任何进程都不能进入下一个阶段。可以通过在每个阶段的结尾
安置**屏障**来实现这种行为。当一个进程到达屏障时，它就会被屏障阻拦，知道所有的进程都到达屏障为止。    


## 2.4 调度

### 2.4.2 批处理系统中的调度

+ **先来先服务**    

这个没什么好说的，非抢占式的先来服务。   

+ **最短作业优先**    

这种算法要求事先知道所有进程的运行时间，并且所有的作业都同时可以运行的情况下才行，反正就是运行时间
少的进程先运行。    

+ **最短剩余时间优先**    

最短作业优先的抢占式版本就是最短剩余时间优先，调剩余运行时间最短的运行，但是还是得知道进程的运行时间。     

### 2.4.3 交互式系统中的调度

+ **轮转调度**    

每个进程被分配一个时间段，称为**时间片**，即允许该进程在时间段中运行。如果在时间片结束后该进程还在
运行，则将剥夺 CPU 并分配给另一个进程。如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换。   

时间片设得太短会导致过多的进程切换，降低了 CPU 效率；而设得太长又可能引起对短的交互请求的响应时间变长。
通过时间片为20~50ms 是合理的折中。    

+ **优先级调度**    

每个进程都被赋予一个优先级，允许优先级最高的可运行进程运行。    

为了防止高优先级进程无休止地运行下去，调度程序可能在每个时钟滴答降低当前进程的优先级。如果这一行为
导致该进程的优先级低于次高优先级的进程，则进行进程切换。另一种方法是给每个进程赋予一个允许运行的最大时间片，当
用完时间片后，次高优先级便获得运行机会。    

很明显，将优先级调度和轮转调度结合起来是比较合理的方法。    

这里需要注意一个批处理系统和交互式系统调度机制的区别，批处理系统在意的是任务的完成效率，吞吐量，周转
时间等，所以尽量少的进行进程切换避免不必要的时间浪费比较重要，而交互式系统更看中对交互指令的响应，
因此需要频繁地切换进程来尽快地对用户的指令做出响应。     

+ **多级队列**     

设立优先级类，属于最高优先级类的进程运行一个时间片，次高优先级类的进程运行两个时间片，再次一级
运行4个时间片，以此类推。当一个进程运行完分配的时间片后，移到下一类。    

