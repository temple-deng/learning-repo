# 第3章 内存管理

操作系统对存储器创建抽象模型的解决方案是分层存储器体系，在这个体系中，计算机有若干兆（MB）快速、
昂贵且易失性的高速缓存（cache），数千兆（GB）速度与价格适中但同样易失性的内存，以及容量更大的、低速、
廉价、非易失性的磁盘存储。     

操作系统中管理分层存储器体系的那部分称为**存储管理器**。它的任务是有效地管理内存，即记录哪些内存是正在
使用的，哪些内存是空闲的；在进程需要时未其分配内存，在进程使用完后释放内存。     

## 3.2 一种存储器抽象：地址空间

将物理地址暴露给进程会带来几个严重的问题，第一，如果用户程序可以寻址内存的每个字节，就可以很容易地
破坏操作系统。第二，使用这种模型同时运行多个程序是困难的，应该是因为静态重定位速度慢且不灵活。    

### 3.2.1 地址空间的概念

要使多个应用程序同时处于内存中的且不互相影响，需要解决两个问题：**保护**和**重定位**。    

地址空间为程序创造了一种抽象的内存。地址空间是一个进程可用于寻址内存的一套地址集合。每个进程都有一个
自己的地址空间，并且这个空间独立于其他进程的地址空间。      

**动态重定位**可以用来解决之前提到的重定位的问题，动态重定位简单的把每个进程的地址空间映射到物理内存的不同
部分。计算机会给每个 CPU 配置两个特殊的硬件寄存器，通常叫做**基址寄存器**和**界限寄存器**。当使用
基址寄存器和界限寄存器时，程序装载到内存中连续的空闲位置且装载期间无须重定位（注意这里提到了装载到
连续的位置，那说明就无法使用后面提到的将正文段和数据段分开的方法把），当一个进程运行时，程序的起始
物理地址装载到基址寄存器中，程序的长度放到界限寄存器中。    

每次进程访问内存，取一条指令，读或写一个数据字，CPU 硬件会在把地址发送到内存总线前，自动把基址值加到进程
发出的地址值上。同时，它检查程序提供的地址是否等于或大于界限寄存器的值。如果访问地址超过了界限，会产生
错误并终止访问（也就可以解决保护的问题）。    

使用这两个寄存器进行重定位的缺点是每次访问内存都要进行加法和比较运算，浪费了时间。    

### 3.2.2 交换技术

有两种处理内存超载的通用方法。最简单的策略是**交换**技术，即把一个进程完整调入内存，使该进程运行一段时间
，然后把它放回磁盘。空闲进程主要存储在磁盘上，所以当它们不运行的时候就不会占用内存。另一种策略是
**虚拟内存**，该策略甚至能使程序在只有一部分被调入内存的情况下运行。其实虚拟内存相当于使用了部分交换技术。    

交换会在内存中产生很多的空闲区，通过把所有进程尽可能的向下移动，有可能将这些空闲区合成一大块。该技术
称为**内存紧缩**。通常不进行这个操作，因为要耗费大量的 CPU 时间（因为要在内存中来回复制数据移动嘛）     

### 3.2.3 空闲内存管理

在动态分配内存时，操作系统必须对其进行管理。一般而言，有两种方法跟踪内存使用情况：位图和空闲区链表。    

思考：所以空闲内存和分页究竟是种怎样的管理呢？    

+ **使用位图的存储管理**     

使用位图方法时，内存可能被划分成小到几个字或大到几千字节的分配单元。每个分配单元对应于位图中的一位，0
表示空闲，1表示占用（或者相反）。     

分配单元的大小是一个重要的设计因素。分配单元越小，位图越大。但是位图占据的内存空间较大。分配单元大
的话，位图则会很小，那么进程分配内存中未使用的内存就会比较多，也会浪费内存。    

+ **使用链表的存储管理**     

使用链表的方法时，会维护一个记录已分配内存段和空闲内存段的链表。其中链表中的一个结点或者包含一个进程，或者是
两个进程间的一块空闲区。链表中的每一个结点都包含以下域：空闲区（H）或进程（P）的指示标志、起始地址、长度
和指向下一结点的指针。其实使用双向链表的结构也不错，在移除进程时相邻的空闲区结点合并时会比较方便。    

当按照地址顺序在链表中存放进程和空闲区时，有几种算法可以用来为创建的进程分配内存。这里，假设存储
管理器知道要为进程分配多少内存。最简单的算法是**首次适配**算法。存储管理器沿着段链表进行搜索，直到
找到一个足够大的空闲区，除非空闲区的大小和分配的空间大小刚好一样，否则将该空闲区分为两部分，一部分供进程
使用，另一部分形成新的空闲区。    

对首次视频算法进行很小的修改就可以得到**下次适配**算法。与首次适配类似，不同的是每次找到合适的
空闲区时都记录当时的位置，以便在下次寻找空闲区时从上次结束的地方开始搜索，而不是每次从头开始（这样有个
问题啊，那在合适的空闲区之前的空闲区岂不是永远得不得使用，应该会隔一段时间从头搜索一次吧）。    

另一个算法是最佳适配，最佳适配会搜索整个链表，找出能够容纳进程的最小的空闲区。      

需要注意的是最佳适配不仅速度要比首次适配和下次适配慢，而且由于最佳适配会尽量找到最合适的空闲区，反而也会
产生很多非常小的空闲区，这些空闲区很难再次应用，因此很可能在浪费的内存空间上也要比前两个多。    

考虑到上面的问题，就出现了**最差适配**，即总是分配最大的可用空闲区。    

综上考虑，好像并没有一种特别出彩的算法，前两种速度不错，但是浪费空间，后两种速度较差，不过可能会浪费
较少的空间。     

如果进程和空闲区使用不同的链表，则可以按照大小对空闲区链表排序，可以提高最佳适配算法的速度。   

还有一种算法是**快速适配**，它为那些常用大小的空闲区维护单独的链表。     

## 3.3 虚拟内存

使用交换技术处理内存超载的问题在于磁盘的速度较慢，如果要整体交换一个占用内存较多的进程，可能会耗费很多的
时间，因此工程师们就想到将进程分成很多段，在需要时才把对应的段装载到内存中，不需要的段可以暂时交换回
磁盘，总体来看可以说是使用了局部交换。    

这种方法就是**虚拟内存**。其基本思想是：每个程序拥有自己的地址空间，这个空间被分割成被分割成多个块，
每一块称作一**页**或**页面**。每一页有连续的地址范围。这些页被映射到物理内存，但并不是所有的页都
必须在内存中才能运行程序。当程序引用到一部分在物理内存中的地址空间时，由硬件执行必要的映射。当程序引用
待一部分不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的命令。  

所以有了虚拟内存的分页机制之后，空闲内存的分配单元大小就变成了一页的大小。应该是这样，嗯嗯。            

### 3.3.1 分页

大部分虚拟内存系统都使用一种叫做**分页**的技术，例如，在计算机上某个程序中会有这样一条指令：    

MOV REG, 1000    

它把地址为1000的内存单元的内容复制到REG中（或者相反，这取决于计算机的型号）。    

由程序产生的这些地址称为**虚拟地址**，它们构成了一个**虚拟地址空间**。在没有虚拟内存的计算机上，
系统直接将虚拟地址送到内存总线上，读写操作使用具有同样地址的物理内存字；而在使用虚拟内存的情况下，
虚拟地址不是被直接送到内存总线上，而是被送到**内存管理单元**（Memory Management Unit, MMU），
MMU 把虚拟地址映射为物理内存地址（然而并没有说清楚是如何对进程的内存进行重定位的呀）。     

所以这里有个问题没有说明，页表应该是在内存中的，那MMU 要转换地址需要到内存中去差页表吧，还是说
MMU 也有存储器，可以直接存储少量的页表项。    

虚拟地址空间按照固定大小划分成被称为页面的若干单元（其实分页是即对进程所用内存分页，也对虚拟内存
进行了分页）。在物理内存中对应的单元叫做**页框**。页面和页框的大小通常是一样的，在实际系统中通常为512B 到1GB。    

当程序访问了一个未映射的页面时，MMU 注意到该页面没有被映射，于是使 CPU 陷入到操作系统，这个陷阱称为
**缺页中断**或**缺页错误**。操作系统找到一个很少使用的页框且把它的内容写入磁盘，随后把需要访问的页面读到
刚才回收的页框中，修改映射关系，然后重新启动引起陷阱的指令。这里真实的顺序是操作系统先将要换出去的
页框的修改为未映射，之后把数据写入，然后修改页面映射。        

具体的地址转换看书吧。以64KB 的虚拟地址和32KB 的物理地址为例，假设分为16个虚拟页和8个页框。则
虚拟地址为16位，前4位为虚拟页表索引，后12位为偏移量，则可以从页表中找到映射的3位的页框号，与12位
偏移量结合起来即可得到15位的物理内存地址。    

这里进程的装载过程可能是这样的，进程先进行分页，然后操作系统分配页号，然后把对应的页号设置为不在，
然后将页面装载到内存中。   

### 3.3.2 页表

页表项的结构是与机器密切相关的，但不同机器的页表项存储的信息都大致相同。通常的页表项代销为32位，其中
最重要的是**页框号**。其次是“在/不在”位。这一位是1时表示该表项是有效的，可以使用；如果是0，则会引起
一个缺页中断。    

**保护**位指出一个页允许什么类型的访问。最简单的形式是这个域只有一位，0表示读/写，1表示只读。一个
更先进的方法是使用三位，分别对应是否启用读、写、执行该页面。    

为了记录页面的使用状况，引入了**修改**位和**访问**位。在写入一个页面时由硬件设置修改位。如果一个页面
已经被修改过，则必须写回磁盘。如果一个页面没修改过，则置换时直接丢弃就行。    

不管是读还是写，系统都会在该页面被访问时设置**访问**位。    

最后一位用于禁止该页面被高速缓存，应该是只有使用 I/O 内存映射的系统才需要这一位，避免 I/O 数据被
缓存。    

### 3.3.3 加速分页过程

任何分页系统都必须考虑两个问题：    

1. 虚拟地址到物理地址的映射必须非常快
2. 如果虚拟地址空间很大，则页表会很大     

这一节介绍如果加速分页的过程：    

+ **转换检测缓冲区**    

为计算机设置一个小型的硬件设备，将虚拟地址直接映射到物理地址，而不必再访问内存中的页表。这种设备叫做
**转换检测缓冲区**（Translation Lookaside Buffer, TLB），有时又称为**相联存储器**或者**快表**，
它通常在 MMU 中，包含少量的表现，在实际中很少超过256个。       

现在看一下 TLB 是如何工作的。将一个虚拟地址放到 MMU 中进行转换时，硬件首先通过将该虚拟页号与 TLB 中所有
页表项同时进行匹配，判断虚拟页面是否在其中。如果发现了一个有效的匹配并且要进行的访问操作不违反保护位，
则将页框号直接从 TLB 中取出而不必再访问页表。如果 MMU 在 TLB 中没有检测到有效的匹配项，就会进行正常的
页表查询，接着从 TLB 中淘汰一个表项，然后用新找到的页表项代替它。      

+ **软件 TLB 管理**    

在上面我们介绍了由 MMU 硬件完全管理 TLB 和处理 TLB 失效问题的情形，不过在许多现代 RISC 机器上，
几乎所有的页面管理都是在软件中实现的，在这些机器上，TLB 表项被操作系统显式地装载。当发生 TLB 访问失效时，
不再是由 MMU 到页表中查找1并取出需要的页表项，而是生成一个 TLB 失效并将问题交给操作系统解决。系统先是
找到该页面，然后从 TLB 中删除一个项，接着装载一个新的项，最后再执行先前出错的指令。     

当使用软件管理 TLB时，一个基本的要求是要理解两种不同 TLB 失效的区别在哪里。当一个页面访问在内存中
而不在 TLB 中时，将产生**软失效**。那么此时所要做的就是更新一个 TLB，不需要产生磁盘 I/O。典型的处理
需要10~20个机器指令并花费几纳秒完成操作。相反，页面本身不在内存中时，将产生**硬失效**。此刻需要一次磁盘存取
以装入该页面，这个过程大概需要几毫秒。     

### 3.3.4 针对大内存的页表

上一节介绍的是如何加速分页的过程，这一节介绍一下针对大内存产生的大量页表项该怎么优化。    

+ **多级页表**      

引入多级页面的原因是避免把全部页表一直保存在内存中。特别是那些从不需要的页表就不应该保留。意思应该是可以把
一些可能访问较少的内存放到一个特定的二级页表中，而这个二级页表由于访问次数比较少，可以放到磁盘上，
这样就可以有效减少内存中的页面占用的空间。    

+ **倒排页表**     

在这种设计中，实际内存中的每个页框对应一个表项（而正常页表是一个虚拟页面对应一个表项，而虚拟页面通常
要比页框多很多，所以这种方法可以较少大量的页表项），表项记录了哪一个（进程，虚拟页面）对定位于该页框。     

虽然倒排页表节省了大量的空间，但是不足的在于从虚拟地址到物理地址的转换会很慢。但进程n访问虚拟页面 p
时，硬件不再能通过把 p 当成指向页表的一个索引来查找物理框。取而代之的是必须搜索整个倒排页表来查找
表项（n, p）。所以这是一种用时间换空间的办法。     

解决上述问题的办法是使用 TLB（但是正常页表也可以使用啊，为什么说倒排页表），实现快速搜索的解法是建立
散列表，用虚拟地址来散列，这样的话倒排页表的页表数目倒是又会少很多，搜索速度可能会加快。      

## 3.4 页面置换算法