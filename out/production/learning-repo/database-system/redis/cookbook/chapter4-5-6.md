# 第 4 章 使用 Redis 进行开发

<!-- TOC -->

- [第 4 章 使用 Redis 进行开发](#第-4-章-使用-redis-进行开发)
  - [4.2 Redis 常见应用场景](#42-redis-常见应用场景)
- [第 5 章 复制](#第-5-章-复制)
  - [5.1 本章概要](#51-本章概要)
  - [5.2 配置 Redis 的复制机制](#52-配置-redis-的复制机制)
  - [5.3 复制机制的调优](#53-复制机制的调优)
- [第 6 章 持久化](#第-6-章-持久化)
  - [6.2 使用 RDB](#62-使用-rdb)
  - [6.4 使用 AOF](#64-使用-aof)

<!-- /TOC -->

## 4.2 Redis 常见应用场景

**会话存储**     

在现代⽹站的架构中，通常多个 Web 服务器位于⼀个或多个负载均衡器之后。会话（Session）通常需要
存储在外部存储系统中。如果有⼀个 Web 服务器宕机，其他的服务器可以从外部存储中获取会话并继续服
务。因为与关系数据库相⽐ Redis 的访问延迟⾮常低，所以使⽤ Redis 来保存会话数据堪称是⼀种完美
的会话存储机制。此外，Redis中对键过期的⽀持可以天然地⽤于会话的超时管理。    

**分析**     

Redis 还可以⽤于分析和统计的场景。例如，如果我们想要计算有多少⽤户查看了⼀个餐厅，那么简单地使⽤
INCR 命令增加统计餐厅被查看数的计数器即可。因为所有的 Redis 命令都是原⼦的，所以我们⽆需担⼼竞态。
基于诸如哈希、有序集合和HyperLoglog等数据类型，我们还可以构建其他更⾼级的计数器或统计数据捕获系统。    

**队列**     

我们在第2章数据类型⼀章中使⽤列表（list）类型的案例中介绍了列表的 PUSH/POP命令（阻塞类型）。
正如我们在那个案例中所演⽰的，Redis 的列表可以⽤来实现简单的任务队列。    

**缓存**    

由于 Redis 是⼀种基于内存的数据存储系统，在关系数据库前⾯使⽤ Redis 作为缓存通常能够加速数据库
的查询过程。在这⾥，让我们举⼀个简单的⽰例：在查询关系数据库之前，我们⾸先在Redis中查找记录。如
果在 Redis 中找不到记录，则查询关系数据库并将记录放到 Redis 中。在向关系数据库写⼊时，我们也
将记录写⼊ Redis。为了限制缓存的⼤⼩，可以对缓存中的记录设置过期时间或应⽤诸如最近最少使⽤
（LeastRecently Used，LRU）的收回策略。     

# 第 5 章 复制

## 5.1 本章概要

Redis 提供了⼀个复制机制，使得数据能够从⼀个 Redis 服务器（master，主实例）复制到⼀个或多个
其他的 Redis 服务器中（slave，从实例）。   

复制不仅提⾼了整个系统的容错能⼒，还可以⽤于对系统进⾏⽔平扩展。在⼀个重读取的应⽤中，我们可以
通过增加多个 Redis 只读从实例来减轻主实例的压⼒。     

Redis 的复制机制是 RedisCluster 的基础，⽽ RedisCluster 在此基础上提供了⾼可⽤性。      

## 5.2 配置 Redis 的复制机制

首先，为 Redis 从实例准备一个配置文件。我们可以将 redis.conf 复制一份并重新命名为 redis-slave.conf，
然后进行以下的修改：    

```
port 6380
pidfile /var/run/redis_6380.pid
dir ./slave
slaveof 127.0.0.1 6379
```    

不要忘记创建 /redis/slave 目录。    

然后使用配置文件 redis-slave.conf 启动一个从实例。    

```
$ bin/redis-server conf/redis-slave.conf
```     

SLAVEOF 同时也是一个可以在 redis-cli 中直接运行的命令，可以动态地将当前 Redis 实例变为另一个
实例的从实例。    

当主从实例之间网络连接通畅且建立了复制关系后，主实例会把将其接收到的写入命令转发给从实例执行，以
实现主从实例之间的数据同步。      

当从实例第一次与主实例连接时会发生什么呢？从实例在网络连接中断后会重新连接到主实例么？在 Redis
的复制机制中，共有两种重新同步机制：部分重新同步和完全重新同步。当一个 Redis 的从实例启动并连接
到主实例时，从实例总是会尝试通过发送（master_replid;master_repl_offset）请求进行部分重新
同步。其中，（master_replid;master_repl_offset）表示与主实例同步的最后一个快照。如果主实例
接受部分重新同步的请求，那么它会从从实例停止时的最后一个偏移处开始增量地进行命令同步。否则，则需要
进行完全重新同步。当从实例第一次连接到它的主实例时，总是需要进行完全重新同步。在进行完全重新同步
时，为了将所有的数据复制到从实例中，主实例需要将数据转储到一个 RDB 文件中，然后将这个文件发送给
从实例。从实例接收到 RDB 文件后，会先将内存中的所有数据清除。再将 RDB 文件中的数据导入。主实例
上的复制过程是完全异步的，因此并不会阻塞服务器处理客户端的请求。   

## 5.3 复制机制的调优

首先通过控制台设置有关主从实例基本信息的变量:    

```cmd
$ M_IP=127.0.0.1
$ M_PORT=6379
$ M_RDB_NAME=master.rdb
$ M_OUT=master.out
$ S1_IP=127.0.0.2
$ S1_PORT=6380
$ S1_OUT=slave_1.out
$ S1_RDB_NAME=slave_1.rdb
```    

启动两个 Redis 实例：    

```cmd
$ nohup /redis/bin/redis-server --port $M_PORT --bind $M_IP --dbfilename $M_RDB_NAME > $M_OUT &
$ nohup /redis/bin/redis-server --port $S1_PORT --bind $S1_IP --dbfilename $S1_RDB_NAME > $S1_OUT &
```    

向一个 Redis 实例中设置一些测试数据：   

```cmd
$ echo set redis hello | nc $M_IP $M_PORT
$ echo lpush num 1 2 3 | nc $M_IP $M_PORT
```    

通过调用 SLAVEOF 命令配置这两个 Redis 实例之间的主从复制。完成主从复制的配置后等待 10 秒钟：   

```cmd
$ echo slaveof 127.0.0.1 6379 | nc $S1_IP $S1_PORT
$ sleep 10
```    

数据同步完成之后，使用 iptables 中断主实例和从实例之间的网络连接：    

```cmd
$ echo "modify iptables"
$ iptables -I INPUT -s 127.0.0.1 -d 127.0.0.2 -j DROP
$ iptabled -I OUTPUT -s 127.0.0.2 -d 127.0.0.1 -j DROP
```   

在网络连接中断期间，向主实例中导入一些测试数据：   

```cmd
$ bash preparerepldata.sh 1000
$ du -sh repl.data
$ cat repl.data | /redis/bin/redis-cli --pipe -h $M_IP -p $M_PORT
```    

然后通过调用 iptables 命令恢复主实例和从实例之间网络连接。在恢复网络连接之前，等待 70 秒：   

```cmd
$ sleep 70
$ echo "restore iptables"
$ iptables -D INPUT -s 127.0.0.1 -d 127.0.0.2 -j DROP
$ iptables -D OUTPUT -s 127.0.0.2 -d 127.0.0.1 -j DROP
```    

等待一段主从实例同步数据时间后，关闭主从实例。删除所有⽇志和转储⽂件。重复前⾯的步骤。这⼀次，我
们增⼤在⽹络断开期间导⼊到主实例中的数据量。    

通过检查主实例和从实例的日志，我们能够发现第一次复制是一次完整的数据同步。因为这是主实例和从实例
之间的第一次同步数据。     

然后我们利用 iptables 切断了网络连接。在网络连接断开期间，我们生成了一些测试数据并导入到了 Redis
主实例中。之后，我们恢复了网络连接，并检查这两个 Redis 实例的日志。    

有趣的是，不同大小的测试数据引发了不同类型的数据重新同步。发生这种情况的原因是，在 Redis 主实例
失去与从实例的网络连接期间，主实例上的一段内存（实际上是一个环形缓冲区）会跟踪最近所有的写入命令。
这个缓冲区实际上是一个固定长度的列表。   

在 Redis 中，我们将这个缓冲区称为 **replication backlog**。Redis 使用这个 backlog 缓冲区
来决定究竟是进行完全重新同步还是部分重新同步。更具体地说，在发出 SLAVEOF 命令后，从实例使用最后
offset 和最后一个主实例的 ID（master_replid）向主实例发送一个部分重新同步的请求。当主实例和从
实例之间的连接建立后，主实例首先会检查请求中的 master_replid 是否与它自己的 master_replid
一致。然后，主实例会检查请求中的 offset 能否从 backlog 缓冲区中获取。如果 offset 位于 backlog
的范围内，那么就可以从中获得连接断开期间的所有写入命令，这也就意味着能够进行部分重新同步。否则，
如果主实例在连接断开期间接收到的写入命令的数量超过了 backlog 缓冲区的容量，那么部分重新同步请求
会被拒绝；此时，完全重新同步将被启动。    

默认情况下，backlog 缓冲区的⼤⼩是 1MB，这个容量在连接断开期间只能容纳少量的写⼊命令。在第⼀次
测试时，我们⽣成并向主实例导⼊了约 96KB 的数据。因此，当从实例再次连接到主实例并请求进⾏部分重新
同步时，主实例能够从 backlog 缓冲区中获取连接断开期间的写⼊命令，并将其发送给从实例。最后，从
实例以部分复制的⽅式追赶上了主实例。     

在第⼆个测试场景中，我们在⽹络连接断开期间⽣成并向主实例导⼊了1.1MB的数据。导⼊数据的⼤⼩⽐
backlog 缓冲区的默认⼤⼩要⼤，因此在重新连接后毫⽆疑问地要执⾏完全重新同步。     

因此我们可能需要调整 repl-backlog-size 这个参数。    

# 第 6 章 持久化

为了保证数据的安全，Redis 提供了将数据持久化到磁盘中的机制。Redis 共有两种数据持久化类型：
RDB 和 AOF。RDB可以看作是 Redis 在某⼀个时间点上的快照（snapshot），⾮常适合于备份和灾难恢
复。AOF 则是⼀个写⼊操作的⽇志，将在服务器启动时被重放。   

## 6.2 使用 RDB

实现持久化的⼀种显⽽易见的⽅法是不断地对存储数据的内存进⾏快照，⽽这基本上正是 Redis 中 RDB 的
⼯作⽅式。    

调用 CONFIG SET 命令，在一个正在运行的 Redis 实例上启用 RDB 持久化：   

```cmd
...> CONFIG SET save "900 1"
OK
...> CONFIG SET save "900 1 300 10 60 10000"
OK
```     

如果想永久性地启用 RDB 持久化，可以在 Redis 配置文件中设置 save 参数：    

```cmd
$ cat conf/redis.conf | grep "^save"
save 900 1
save 300 10
save 60 10000
```    

要在一个正在运行的 Redis 实例上禁用 RDB 持久化，可以使用 redis-cli 把 save 参数设为空字符串：   

```cmd
$ bin/redis-cli config set save ""
OK
```    

要禁用 RDB 持久化，只需在配置文件中注释掉或删除 save 参数。   

通过 redis-cli 获取 save 选项的值可以判断是否启用了 RDB 功能。如果 save 选项是一个空字符串，
则表示 RDB 功能是被禁用的。否则，则返回 RDB 快照的触发策略。    

如果要手动执行 RDB 快照，在 redis-cli 中调用 save 命令即可，redis-cli 将会被阻塞一段时间，
然后命令提示符会返回如下内容：    

```cmd
...> SAVE
OK
(23.25s)
```     

或者我们也可以调用 BGSAVE 命令来执行非阻塞的 RDB 转储：    

```cmd
...> BGSAVE
Background saving started
```    

RDB 就像是一台专门给 Redis 数据存储拍照的照相机。当满足触发策略时，Redis 会通过将所有数据转储
到本地磁盘上一个文件中的方式给 Redis 中的数据拍一张“照片”。在详细介绍上述过程前，我们先来解释
以下 save 参数的含义。save 参数决定了提到的 RDB 触发策略，这个值的格式 x1, y1, x2, y2....，
其含义是，如果超过 y 个键发生改变且此时没有转储正在发生，则在 x 秒后进行数据转储。    

在前⾯的⽰例中，900 1 表⽰如果在900秒内有超过1个键发⽣了改变，则会进⾏⼀次RDB快照。在 save
选项中，可以同时使⽤多个策略来控制RDB快照执⾏的频率。    

通过 SAVE 或 BGSAVE 命令可以手动启动一次 RDB 转储。这两个命令的不同之处在于，前者使用 Redis
主线程进行同步转储，而后者则在后台进行转储。因为 Save 命令会阻塞服务器，所以永远不要在生产环境
使用。与之不同，对于 BGSAVE 命令而言，Redis 主线程将继续处理收到的命令，同时会通过 `fork()`
系统调用创建一个子进程将转储数据保存到一个名为 `temp-<bgsave-pid>.rdb` 的临时文件中。当转储
过程结束后，这个临时文件会被重命名为由参数 dbfilename 定义的名字并覆盖由参数 dir 指定的本地
目录中的旧转储文件。    

如果要还原 RDB 快照，我们需要把快照文件复制到 dir 选项指定的位置，并且保证启动 Redis 实例的
用户有该文件的读/写权限。之后，我们通过 SHUTDOWN NOSAVE 命令停止实例，并将新转储文件重命名为
dbfilename 选项定义的名字。重新启动后，数据就会从备份文件中加载并还原回 Redis 了。    

没看懂还原这。    

## 6.4 使用 AOF

使用 RDB 进行数据持久化并不能提供非常强的一致性。一个 RDB 数据转储文件仅包含某个时间点上的 Redis
数据快照。虽然外面可以定期地将数据转储到 RDB 文件中，但当 Redis 进程崩溃或者出现硬件故障时，
两次 RDB 转储之间的数据将会永久丢失。    

AOF（append-only file）是一种只记录 Redis 写入命令的追加式日志文件。因为每个写入命令都会被
追加到文件中，所以 AOF 的数据一致性比 RDB 更高。    

坑爹，在正在运行的 Redis 实例上启用 AOF 持久化的内容又丢掉了。    

如果想永久性地启⽤ AOF 持久化，可以在 Redis 配置⽂件中添加 appendonly yes，然后重新启动服务器。   

```cmd
$ cat conf/redis.conf | grep "^appendonly"
appendonly yes
```     

要想在一个正在运行的的 Redis 实例上禁用 AOF 持久化，可以把 appendonly 参数设为 no：    

```cmd
$ bin/redis-cli config set appendonly no
OK
```    

要永久地禁⽤ AOF 持久化，只需在配置⽂件中设置 appendonly no 并重新启动服务器.    

当 AOF 功能被启用时，Redis 将会在数据目录中创建 AOF 文件。AOF 文件的默认文件名是 appendonly.aof，
并通过配置文件中的 appendfilename 参数进行修改。同时，Redis 还会将当前内存中的数据填充到这个
AOF 文件中。    

每当 Redis 服务器接收到一个会实际修改内存数据的写入命令时，Redis 会将该命令追加到 AOF 文件中。
但是，如果我们深入研究 AOF 文件的写入过程，就会发现操作系统实际上维护了一个缓冲区，Redis 的命令
首先会被写入到这个缓冲区中。而缓冲区中的数据必须被刷新到磁盘中，才能被永久保存。这个过程是通过
Linux 系统调用 `fsync()` 完成的，这是一个阻塞调用，只有磁盘设备报告缓冲区中的数据写入完成后
才会返回。    

在将命令追加到 AOF 文件时，我们可以通过 Redis 的配置参数 append fsync 来调整调用 `fsync()`
的频率。该参数共有三个选项：   

- always: 对每个写入命令都调用 `fsync()`。这个选项可以确保在发生意外的服务器崩溃或硬件故障时，
只丢失一个命令。但是，由于 `fsync()` 是一个阻塞调用，Redis 的性能会受到物理磁盘写入性能的限制。  
- everysrc: 每秒调用一次 `fsync()`。采用这一选项时，在意外灾难事件中只有一秒钟的数据会丢失。
- no: 永远不调用 `fsync()`。采用该选项时，将由操作系统决定何时将数据从缓冲区写入到磁盘。在大多数
Linux 系统中，这个频率是每 30 秒。    

当Redis服务器关闭时，`fsync()` 会被显式地调⽤，以确保写⼊缓冲区中的所有数据都会被刷新到磁盘中。    

当Redis服务器启动时，AOF ⽂件会被⽤来恢复数据。Redis 只需要通过读取命令来重放⽂件，并将它们逐
个应⽤到内存中即可。待所有命令都被处理完之后，数据也就被重建好了。    

随着 Redis 将写⼊命令追加到 AOF ⽂件中，AOF ⽂件的⼤⼩可能会显著增加；⽽这会拖慢Redis启动时
的数据重建过程。Redis提供了⼀种机制，即通过AOF重写（AOF rewrite）来压缩 AOF ⽂件。读者可能
已经猜到，Redis 中的某些键可能已经被删除或过期了，所以可以在 AOF ⽂件中将其清除；同时，某些键
的值可能被更新了多次，但只有最新的值才需要存储在 AOF ⽂件中。这就是 AOF 重写中数据压缩的基本思想。
我们可以使⽤ BGREWRITEAOF 命令来启动重写过程，或者让 Redis ⾃动执⾏ AOF 重写。    

