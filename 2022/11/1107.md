## 1107   

### Media Source API

Media Source API 即之前的 Media Source Extensions，主要是提供 video, audio 元素播放流数据的机制。    

之前像 video 元素的 src 属性，只能赋值给一个单独轨道的媒体资源，现在的话可以传递一个 Media Source 对象。这个对象是一个容器，包含了媒体资源的 ready state，包含了对个 SourceBuffer 对象的引用，而 SourceBuffer 对象代表了组成整个流的媒体的不同 chunk。   

### MediaSource 对象

- `MediaSource()`: 构造函数
- 实例属性：
  + `sourceBuffers`: `SourceBufferList`
  + `activeSourceBuffers`: `SourceBufferList`，上个属性的子集，相当于只包含选中的音视、字幕轨道的 SourceBuffer 对象
  + `readyState`: enum
    - `closed`: source 当前没有绑定到一个媒体元素上
    - `open`: source 绑定到了媒体元素上，且准备好了接收 SourceBuffer 对象，所以看这个意思是，理论上先创建对象，然后赋值给媒体元素进行绑定，后面才可以添加 SourceBuffer 对象。
    - `ended`: source 绑定到了媒体元素上，但是流已经被 `MediaSource.endOfStream` 关闭了。    
  + `duration`: number，读取或者设置当前播放媒体的时长
- 实例方法
  + `addSourceBuffer(mimeType)`: `SourceBuffer`，创建一个新的 SourceBuffer 复习，然后添加到 MediaSource 的 sourceBuffers 列表中
  + `clearLiveSeekableRange()`: 清除掉一个之前通过调用 `setLiveSeekableRange` 设置的 seekable range.
  + `endOfStream(endOfStreamError?: string)`: 发出流结束的信号
  + `removeSourceBuffer(sourceBuffer)`
  + `setLiveSeekableRange(start, end)`
- 静态方法
  + `isTypeSupported(type)`
- 事件
  + `sourceclose`: 当 source 实例不再和一个媒体元素绑定时
  + `soruceended`: source 仍然和媒体元素绑定，但是已经调用过 `endOfStream`
  + `sourceopen`: 就绑定了媒体元素，且准备好接收 sourceBuffer 对象

```js
const video = document.querySelector('video');

const assetURL = 'frag_bunny.mp4';
// Need to be specific for Blink regarding codecs
// ./mp4info frag_bunny.mp4 | grep Codec
const mimeCodec = 'video/mp4; codecs="avc1.42E01E, mp4a.40.2"';
let mediaSource;

if ('MediaSource' in window && MediaSource.isTypeSupported(mimeCodec)) {
  mediaSource = getMediaSource();
  console.log(mediaSource.readyState); // closed
  video.src = URL.createObjectURL(mediaSource);
  mediaSource.addEventListener('sourceopen', sourceOpen);
} else {
  console.error('Unsupported MIME type or codec: ', mimeCodec);
}

function sourceOpen() {
  console.log(this.readyState); // open
  const sourceBuffer = mediaSource.addSourceBuffer(mimeCodec);
  fetchAB(assetURL, (buf) => {
    sourceBuffer.addEventListener('updateend', () => {
      mediaSource.endOfStream();
      video.play();
      console.log(mediaSource.readyState); // ended
    });
    sourceBuffer.appendBuffer(buf);
  });
};

function fetchAB (url, cb) {
  console.log(url);
  const xhr = new XMLHttpRequest;
  xhr.open('get', url);
  xhr.responseType = 'arraybuffer';
  xhr.onload = () => {
    cb(xhr.response);
  };
  xhr.send();
};
```     

### SourceBuffer 对象

- 实例属性
  + `appendWindowEnd: number`
  + `appendWindowStart: number`
  + `audioTracks: AudioTrackList`
  + `buffered: TimeRanges`
  + `mode: enum`
    - `segments`: 媒体段落的时间戳决定了媒体播放的顺序，段落可以以任意顺序添加到 SourceBuffer 中
    - `sequence`: 段落添加的顺序决定了段落播放的顺序，自动生成段落的时间戳
  + `textTracks: TextTrackList` 
  + `timestampOffset: number`
  + `updating: boolean`: 当前 SourceBuffer 对象是否在更新中，比如`appendBuffer(), remove()` 操作正在进行中
  + `videoTracks: VideoTrackList`
- 实例方法
  + `abort()`: abort 当前的段落，重置段落解析器
  + `appendBuffer: ArrayBuffer | TypedArray | DataView`: 添加媒体段落数据到 SourceBuffer 中，问题来了，在 appendBuffer 的时候，是一下子就完成了同步操作，还是个异步操作，如果是异步，当完成前，能播放之前的东西吗。
  + `remove(start, end)`: 移除指定时间区间的媒体段落
- 事件：
  + `abort`: 从这个描述来看，`appendBuffer` 应该是个异步操作，在操作过程 updating 是 true, 这个过程中可以调用 abort() 触发取消
  + `error`
  + `update`: 当 `appendBuffer` 或者 `remove` 完成时触发，updating 从 true 变成 false。
  + `updateend`: 当 `appendBuffer` 或者 `remove` 结束时触发，所以这个可能是正常完成，也可能是 abort 了？
  + `updatestart`: updating 从 false 变为 true 时触发


```js
const video = document.getElementsByClassName('video')[0];

const mediaSource = new MediaSource();
const mime = 'video/mp4; codecs="avc1.42E01E, mp4a.40.2"';


mediaSource.addEventListener('sourceopen', () => {
    URL.revokeObjectURL(video.src);
    const sourcebuffer = mediaSource.addSourceBuffer(mime);

    fetch('frag_bunny.mp4')
        .then(res => {
            return res.arrayBuffer();
        }).then((buf) => {
            sourcebuffer.addEventListener('updateend', () => {
                mediaSource.endOfStream();
                video.play();
            });

            sourcebuffer.appendBuffer(buf);
        });
});

video.src = URL.createObjectURL(mediaSource);
```    

### HLS


生成一个 .m3u8 文件，其中除了包含一些元数据，还记录被分割视频的存放位置。分割的视频是 .ts 结尾的文件，是 MPEG-2 Transport Stream 容器，不过现在 HLS 也支持 fmp4。     

```m3u8
#EXTM3U
#EXT-X-TARGETDURATION:10
#EXT-X-VERSION:4
#EXT-X-MEDIA-SEQUENCE:0
#EXTINF:10.0,
ad0.ts
#EXTINF:8.0,
ad1.ts
#EXT-X-DISCONTINUITY
#EXTINF:10.0,
movieA.ts
#EXTINF:10.0,
movieB.ts
```    

文件中以 # 开头的字符串要么是注释，要么就是标签，标签以 #EXT 开头，大小写敏感。    

- EXTM3U M3U8 文件必须包含的标签，并且必须在文件的第一行
- EXT-X-VERSION M3U8 文件的版本，常见的是 3（目前最高版本应该是7），版本更高支持的标签就越多
- EXT-X-TARGETDURATION 指定了单个媒体文件持续时间的最大值
- EXT-X-MEDIA-SEQUENCE 播放列表第一个 URL 片段文件的序列号，默认序列号从 0 开始
- EXTINF 其后 URL 指定的媒体片段时长（秒）
- EXT-X-DISCONTINUITY 一般用于视频流中插入广告，表示前面的片段与后面不一样，让客户端做好准备

hls 通过两层 m3u8 来实现自适应码率。苹果的设备都支持 hls，所以直接设置 video 的 src 为 m3u8 文件就可以了。    

### DASH

与 HLS 不同的是 DASH 是 国际标准，而 HLS 属于苹果公司。并且 DASH 支持任何编码，它就可以用 vp9 编码的 webm 格式视频。目前有很多大视频网站都在使用 DASH，比如 youtube、netflix、bilibili。    

DASH 的索引文件是 .mpd（Media Presentation Description） 结尾的 XML 文件.   