# 0309

<!-- TOC -->

- [0309](#0309)
  - [Media Capture and Streams API](#media-capture-and-streams-api)
    - [能力，限制与设置](#能力限制与设置)
      - [应用 constraints](#应用-constraints)
      - [获取 constraints](#获取-constraints)
      - [获取当前的 settings](#获取当前的-settings)

<!-- /TOC -->

## Media Capture and Streams API

即 Media Stream API，主要就是提供给 WebRTC 用的。    

核心就是通过对 `MediaStream` 操作，处理视频流。一个使用流的简单例子，拍照功能，可以，很有意思。   

```html
<button id="start">Start up</button>
    <button id="close">Close</button>
    <div class="camera">
        <video src="" id="video"></video>
        <button id="startbutton">Take photo</button>
    </div>

    <canvas id="canvas">
        <div class="output"><img src="" alt="" id="photo"></div>
    </canvas>

    <script src="./camera.js" type="module"></script>
```   


```js
const width = 320;
let height = 0;
let streaming = false;

const getEl = id => document.getElementById(id);

let video = null;
let canvas = null
let photo = null
let starbutton = null
let start = getEl('start');
let close = getEl('close');

console.log('hh');

start.addEventListener('click', () => {
    startup();
});
close.addEventListener('click', () => {
    video.pause();
});

function startup() {
    video = getEl('video');
    canvas = getEl('canvas')
    photo = getEl('photo')
    starbutton = getEl('startbutton')

    navigator.mediaDevices.getUserMedia({video: true, audio: true})
        .then((stream) => {
            video.srcObject = stream;
            video.play();
        })
        .catch((err) => {
            console.log('An error occurred: ' + err);
        });

    video.addEventListener('canplay', (evt) => {
        if (!streaming) {
            height = video.videoHeight / (video.videoWidth / width);
            video.setAttribute('width', width);
            video.setAttribute('height', height);
            canvas.setAttribute('width', width);
            canvas.setAttribute('height', height);
            streaming = true;
        }
    })

    starbutton.addEventListener('click', (evt) => {
        evt.stopPropagation();
        takePicture();
    })

}


function clearPhoto() {
    const ctx = canvas.getContext('2d');
    ctx.fillStyle = '#AAA';
    ctx.fillRect(0, 0, canvas.width, canvas.height);
    const data = canvas.toDataURL('image/png');
    photo.setAttribute('src', data);
}

function takePicture() {
    const ctx = canvas.getContext('2d');
    if (width && height) {
        canvas.width = width;
        canvas.height = height;

        ctx.drawImage(video, 0, 0, width, height);
        photo.setAttribute('src', canvas.toDataURL('image/png'));
    } else {
        clearPhoto();
    }
}
```    

一个 `MediaStream` 对象包含了0或多个 `MediaStreamTrack` 对象，代表了不同的视频、音频的轨道 track。
那可以理解为一个流中包含了多个音视频轨。    

每个 `MediaStreamTrack` 又可以有一个到多个 channels。channel 代表了媒体流中的最小的单元。比如立体声音频中
一个音道，左声道，或者右声道。    

`MediaStream` 对象有唯一的一个 input 和唯一的一个 output。通过 `getUserMedia()` 方法生成的 `MediaStream`
对象称为 local 的，将用户的摄像头或者麦克风作为源输入。而一个非 local 的 `MediaStream` 对象，通常代表一个
媒体元素，像是 `<video>`, `<audio>`，也可以代表一个网络传输的流，通过 WebRTC RTCPeerConnection API 捕获到，
或者是一个使用 Web Audio API MediaStreamAudioDestinationNode 创建的流。    

`MediaStream` 的输出会链接到一个 consumer。可能是一个媒体元素，或者是一个 WebRTC 和 Web Audio 中的流。   

### 能力，限制与设置    

Capabilities and constraints 可以让浏览器和 app 交换信息，让 app 知道浏览器支持哪些受限制的属性与属性值。   

整个流程差不多这样：   

1. 有必要的情况，调用 `MediaDevices.getSupportedConstraints()` 获取支持的限制列表，包含了浏览器知道的 constrainable properties。这一步不总是有必要，因为一般来说哪些浏览器不清楚的在指定的时候会被浏览器直接忽略
2. 一旦脚本知道了它希望使用的属性是支持的，就可以使用 `getCapabilities()` 获取 API 的能力
3. 最后，track 的 `applyConstraints` 方法用来配置使用其更喜欢使用的限制属性

在 Media Stream API 中，`MediaStream` 和 `MediaStreamTrack` 都有受限制的属性。    

```js
let supported = navigator.mediaDevices.getSupportedConstraints();
// 在本地是打印出以下的内容
supported = {
    "aspectRatio": true,
    "autoGainControl": true,
    "brightness": true,
    "channelCount": true,
    "colorTemperature": true,
    "contrast": true,
    "deviceId": true,
    "echoCancellation": true,
    "exposureCompensation": true,
    "exposureMode": true,
    "exposureTime": true,
    "facingMode": true,
    "focusDistance": true,
    "focusMode": true,
    "frameRate": true,
    "groupId": true,
    "height": true,
    "iso": true,
    "latency": true,
    "noiseSuppression": true,
    "pan": true,
    "pointsOfInterest": true,
    "resizeMode": true,
    "sampleRate": true,
    "sampleSize": true,
    "saturation": true,
    "sharpness": true,
    "tilt": true,
    "torch": true,
    "whiteBalanceMode": true,
    "width": true,
    "zoom": true
}
```    

理解了，这些所谓的 constraints 是指我们可以对 stream 施加的限制，比如说支持 width, height，那我们
可能就可以设置 stream 的宽高。   

```js
let constranits = {
    width: 1920,
    height: 1080,
    aspectRatio: 1.7777778,
};

myTrack.applyConstraints(constranits);
```

如果两个属性的请求值是相斥的，那列表中先出现的那个会被使用，比如说浏览器不能提供 1920*1080 的，但是可以提供
1920*900 的，那就使用这个。    

一般来说，在合法范围中任何值都是可以接受的。可以指定最大最小值，以及一个理想值。    

```js
let supports = navigator.mediaDevices.getSupportedConstraints();

if (!supports['width'] || !supports['height'] || !supports['frameRate'] || !supports['facingMode']) {
    // We're missing needed properties, so handle that error.
} else {
    let constraints = {
        width: {
            min: 640,
            ideal: 1920,
            max: 1920,
        },
        height: {
            min: 400,
            ideal: 1080,
        },
        aspectRatio: 1.777778,
        frameRate: { max: 30 },
        facingMode: { exact: 'user' },
    };

    myTract.applyConstraints(constraints)
        .then(() => {
            // ....
        })
        .carch((reason) => {
            // ...
        });
}
```     

一般来说，认为使用 max, min, exact 指定的是强制的要求，所以如果这种的请求无法满足，会 reject。    

除了普通的限制之外，还可以添加一个 `advanced` 属性添加高级配置，属性值是一个数组。这里暂时不说了。    

使用 `MediaStreamTrack.getCapabilities()` 获取当前浏览器支持的所有的能力，及能力可取的值。
函数返回 `MediaTrackCapabilities` 对象。    

不过这个 API 目前貌似都还没什么实现了的浏览器。    

#### 应用 constraints

最常见的方式是在使用 `getUserMedia()` 的时候：    

```js
navigator.mediaDevices.getUserMedia({
    video: {
        width: {min: 640, ideal: 1920},
        height: {min: 640, ideal: 1080},
        aspectRatio: {ideal: 1.7777778},
    },
    audio: {
        sampleSize: 16,
        channelCount: 2
    }
}).then(stream => {
    videoElement.srcObject = stream;
})
```    

另一种方式就是在使用 `MediaStreamTrack` 的过程中，调用 `applyConstraints()` 方法。   

constraints 是指我们希望的值，而 settings 是最终使用的值。    

#### 获取 constraints

获取当前的

```js
function switchCameras(track, camera) {
    let constraints = track.getConstraints();
    constraints.facingMode = camera;
    track.applyConstraints(constraints);
}
```

#### 获取当前的 settings    

```js
function whichCamera(track) {
    return track.getSettings().facingMode;
}
```