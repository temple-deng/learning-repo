## 0310

<!-- TOC -->

- [0310](#0310)
  - [mediaDevices](#mediadevices)
  - [MediaDeviceInfo](#mediadeviceinfo)
  - [MediaTrackSupportedConstraints](#mediatracksupportedconstraints)
  - [MediaStream](#mediastream)
  - [MediaStreamTrack](#mediastreamtrack)
  - [WebRTC API](#webrtc-api)
    - [连接建立和管理](#连接建立和管理)
  - [WebRTC 协议](#webrtc-协议)
  - [Signaling and video calling](#signaling-and-video-calling)
    - [信令服务器](#信令服务器)
    - [代码部分](#代码部分)

<!-- /TOC -->

### mediaDevices    

返回 `navigator.mediaDevices` 返回一个 `MediaDevices` 对象，提供了对媒体输入设备
比如说摄像头、麦克风及屏幕共享的访问。    

MediaDevices 对象，继承自 EventTarget。   

- 事件：
  + devicechange: 当用户设置有输入输出设备变动
- 方法
  + `enumerateDevices()`: 返回一个 Promise, resolved 为一个 `MediaDeviceInfo` 数组，表示当前系统可用的输入输出设备。
  + `getSupportedConstraints()`: 返回一个基于 `MediaTrackSupportedConstraints` 字典的对象，因为只有浏览器支持的才会包含在对象中，所以所有属性值都是 true。
  + `getDisplayMedia(constraints)`: 貌似是用来屏幕共享的功能，提示用户选择并授权，将显示内容或其部分捕获为 MediaStream。类似下面的样子，也是返回一个 Stream 的 Promise。
  + `selectAudioOuput(options)`: 提示用户选择一个音频输出设备，返回选择设备 MediaDeviceInfo 的 Promise
  + `getUserMedia(constraints)`: 提示用户申请对媒体设备的使用，生成一个 MediaStream，包含请求的设备类型的 track。一般来说 stream 可以包含一个 video track, 一个 audio track，及其他 track 类型。返回一个 Stream Promise。
    - constraints 只有两个成员 video, audio。

![getDisplayMedia](https://cdn.jsdelivr.net/gh/temple-deng/learning-repo/imgs/getDisplayMedia.png)



### MediaDeviceInfo

- deviceId: 设备 id，一般在不同会话间是一致的，但注意是会话间，不是持久化，清空 cookie 就会重置
- groupId: 返回组 id，如果两个 device 属于同一个物理设备，就用一个组 id
- kind: 枚举值，`videoinput`, `audioinput`, `audiooutput`
- label


### MediaTrackSupportedConstraints    

字典属性值：   

- `autoGainControl`
- `width`
- `height`
- `aspectRatio`
- `frameRate`
- `facingMode`
- `resizeMode`
- `volume`
- `sampleRate`
- `sampleSize`
- `echoCancellation`
- `latency`
- `noiseSuppression`
- `channelCount`
- `deviceId`
- `groupId`    


### MediaStream    

表示一个媒体内容流，包含了多个 tracks。每个 track 都是一个 `MediaStreamTrack` 实例。    

通过下面的方式可以获取流：   

- `MediaDevices.getUserMedia()`
- `MediaDevices.getDisplayMedia()`
- `HTMLCanvasElement.captureStream()`    

+ 属性：
  - active: 只要其中的 track 有一个不是 ended 状态，就可以认为是 active
  - id
+ 方法：
  - `addTrack(track)`
  - `clone()`
  - `getAudioTracks()`
  - `getTrackById()`
  - `getTracks()`
  - `getVideoTracks()`
  - `removeTrack()`
+ 事件：
  - addtrack
  - removetrack
  - active
  - inactive

### MediaStreamTrack

属性：   

- contentHint: 就是个提示的字符串，用来告诉 app 这个 track 的内容是什么类型的
- enabled
- id
- kine: audio, video
- label
- muted
- readyState: live, ended
- remote

方法：   

- `applyConstraints()`
- `clone()`
- `getCapabilities()`
- `getConstraints()`
- `getSettings()`
- `stop()`     



### WebRTC API

由于 WebRTC 仍在进化过程中，而且各家浏览器对编码器和 WebRTC 功能的支持度也不同，
推荐使用 G 家的 Adapter.js（https://github.com/webrtcHacks/adapter）作为 polyfill。    

两个端点间的连接使用 `RTCPeerConnection` 接口表示。一旦建立了连接，并且使用
`RTCPeerConnection` 打开，就可以将 streams 或者 data channels(`RTCDataChannels`) 添加到连接中去。    

所以 RTC 不仅仅能用来传输流，还可以用来传递任意的二进制数据。   

#### 连接建立和管理    

接口：   

- `RTCPeerConnection`: 表示本地到远程对等方的一个 WebRTC 连接。用来高效的处理流的数据
- `RTCDataChannel`: 代表一个连接两个对等方之间的双向数据通道
- `RTCDataChannelEvent`: 将 `RTCDataChannel` attach 到 `RTCPeerConnection` 上发生的事件
- `RTCSessionDescription`: 代表一个会话的参数。每个 `RTCSessionDescription` 包含一个 type 表示其描述了 offer/answer 协商过程中的哪一部分，以及属于会话 SDP 描述符的哪一部分
- `RTCStatsReport`: 提供对于连接信息细节的数据
- `RTCIceCandidate`: 代表一个用于建立 `RTCPeerConnection` 的 candidate Interactive Connectivity Establishment(ICE) 服务器
- `RTCIceTransport`: 表示一个 ICE transport 的信息
- `RTCPeerConnectionIceEvent`


算了太多了，先跳过这一部分。    

### WebRTC 协议

Interactive Connectivity Establishment(ICE) 交互式连接建立是一个允许浏览器和对等方连接的框架。可以提供给我们一个唯一的地址，在路由器不准直连对等方的时候，提供一个中转
数据的服务器。ICE 使用 STUN、TURN 服务器完成这些工作。    

Session Traversal Utilities for NAT(STUN) 是一种协议，用于发现您的公共地址，并确定路由器中阻止与对等方直接连接的任何限制。   

C 端会给 STUN 服务器发送请求，然后 STUN 会回复 C 的公开地址，以及是否能访问到 NAT 后的 C 端。    

Traversal Using Relays around NAT(TURN) 可以绕过路由器的限制，做法就是通过一个 TURN 服务器中转所有数据。这时候双方就是先和 TURN 服务器交流，再转发到另一方。   

Session Description Protocol(SDP) 是一个标准，描述连接中的多媒体内容，比如说分辨率、
格式、编解码器、加密等。以便在数据传输后，两个对等方能互相理解。本质上，这是描述内容的元数据，而不是媒体内容本身。    

本质上，SDP 不是一个协议，而是一种用来交换信息的格式。   

SDP 包括了多行 UTF-8 文本，每行以一个字符类型开头，后跟一个等号 "="，后面是由值或描述组成的结构化文本，其格式
取决于类型。以给定字母开头的文本化通常称为"字母行"。    

### Signaling and video calling

连接建立时的发现及沟通过程称为 signaling。   

#### 信令服务器

WebRTC 并没有指定信令信息的传输机制。所以本质上我们可以自己选择，websocket, xhr 都是对等方可以选择的方式。   

很重要的一点是，服务器并不需要理解或解释信令数据的内容。也就是说信令服务器本质上并不关系数据的内容，它要做的就
只是传输数据。   

当我们开始信令的处理流程时，用户初始化调用的时候会创建一个 offer。这个 offer 是 SDP 格式，包含了会话的描述信息。
需要传递给对等方。对等方会使用一个 answer message 响应我们的 offer，同样也是 SDP 格式的消息。    

这个时候，双方就交换好了一些数据，比如编解码器等等，但是目前还不知道如何传递媒体数据本身，这时候就需要 ICE 了。   

两个对等方需要交换 ICE 来协商数据连接的情况。每个 ICE candidate 描述了发送方用来交流的方法。每个对等方
会在被发现的时候发送 candidate。    

icecandidate 事件会发送给 RTCPeerConnection，以完成使用 `pc.setLocalDescription(offer)` 添加本地描述的
过程。这一个没看懂啥意思。    

每个 ICE candidate 会发送一个 type 为 new-ice-candidate 的 json 消息给对等方，通过信令服务器，每个
candidate 消息包括以下字段:   

- type: new-ice-candidate
- target: 正在与之协商的人的用户名；服务器会仅将消息定向到此用户
- candidate: SDP candidate 字符串，描述提议的连接方法。   

ice message 会提议交流协议（tcp or udp），ip地址，端口号，连接类型（直连还是中转）。   

我们代码在 ICE 协商过程中唯一需要负责的事就是接受 ICE 层提供的 candidate，然后在 onicecandidate
事件回调中将其通过信令连接发送给另一个对等方，然后等待接收从信令服务器发送的 ICE candidate 消息，然后调用
`RTCPeerConnection.addIceCandidate()` 将其交给 ICE 层。    

![video-calling](https://cdn.jsdelivr.net/gh/temple-deng/learning-repo/imgs/video-calling.svg);

![ice](https://cdn.jsdelivr.net/gh/temple-deng/learning-repo/imgs/ice.svg);

#### 代码部分   

部分代码内容，主要看一下将 track 添加到 connection 中的操作：   

```js
createPeerConnection();

navigator.mediaDevices.getUserMedia(mediaConstraints)
.then(function(localStream) {
  document.getElementById("local_video").srcObject = localStream;
  localStream.getTracks().forEach(track => myPeerConnection.addTrack(track, localStream));
})
.catch(handleGetUserMediaError);
```    

然后下面是自己写的代码：    

```ts
const handleICECandidate = useCallback(() => {

}, []);

const handleTrack = useCallback(() => {

}, []);

const handleNegoed = useCallback(() => {}, []);

const handleRemoveTrack = useCallback(() => {}, []);

const handleConnectionChange = useCallback(() => {}, []);

const handleGatherChange = useCallback(() => {}, [])

const handleSignalChange = useCallback(() => {}, []);

const createPeerConnenction = () => {
    const peer = new RTCPeerConnection({
        iceServers: [
            {
                urls: 'stun:localhost:3000'
            }
        ]
    });

    connectionRef.current = peer;
    peer.addEventListener('icecandidate', handleICECandidate);
    peer.addEventListener('track', handleTrack);
    peer.addEventListener('negotiationneeded', handleNegoed);
    peer.addEventListener('removetrack', handleRemoveTrack);
    peer.addEventListener('iceconnectionstatechange', handleConnectionChange);
    peer.addEventListener('icegatheringstatechange', handleGatherChange)
    peer.addEventListener('signalingstatechange', handleSignalChange)
};

const handleOpenVideo = () => {
    createPeerConnenction();
    navigator.mediaDevices.getUserMedia({video: true})
        .then(st => {
            streamRef.current = st;
            console.log(videoRef.current);
            if (videoRef.current) {
                videoRef.current.srcObject = st;
                videoRef.current.play();
                setPlaying(true);
            }
        })
        .catch((e) => {
            console.log('视频 stream 获取失败', e);
        })
}
```    

iceServers 参数就像其名所述，一个对象数组，描述了 ICE 层使用的 STUN 和 TURN 服务器地址。这些服务器会
用来决定对等方间通信的最佳路由和协议。    

具体事件的解释：    

- icecandidate: 当 ICE 层需要我们去传输 ICE candidate 给对等方时，就会触发这个事件。
- track: 当一个 track 添加到 connection 中，WebRTC 层触发。主要是用来将到来的媒体数据绑定到一个元素上，以便展示
- negotiationneeded： 每当 WebRTC 基础设施需要我们重新启动会话协商过程时，就会调用此函数
- removetrack: 当对等方用媒体流中移除了一个 track 时触发
- iceconnectionstatechange：ice 连接状态变化时触发
- icegatheringstatechange：当 ICE 代理处理收集 candidate 的过程状态转移到另一个状态时触发
- signalingstatechange: 信号处理过程状态变化时触发

一旦一方创建了 `RTCPeerConnection`，创建了一个 media stream 然后将其 track 添加到 connection 中后，
浏览器就会触发一个 `negotiationneeded` 事件，表示其准备好了和另一个对等方协商了。    

```js
this.connection.createOffer()
        .then(offer => {
            return this.connection!.setLocalDescription(offer);
        })
        .then(() => {
            this.props.onSendOffer(this.state.connectId, this.connection!.localDescription);
        })
        .catch((e) => {
            console.log('send offer error', e);
        })
```    

要开始协商流程，首先要创建并发送 SDP offer 给对等方，这个 offer 包括一系列连接的支持的配置，包括我们要发送
给对方的媒体流的信息，以及 ICE 层收集到的 ICE candidate。   

`setLocalDescription` 是配置我们这一方的连接和媒体状态。当这个返回 Promise fulfiied 时，表示 description
设置好了。    

一旦 `setLocalDescription` fulfilled，ICE 代码会发送 `icecandidate` 事件。这个事件负责把 candidate 发送
给对等方。    

这有点乱啊，到底 candidate 是在 offer 中还是这里单发的，感觉这里单发可能性比较大。    

```js
handleSendOffer = (id: number, sdp?: RTCSessionDescription | null) => {
  this.socket.emit(SEND_OFFER, {
    to: id,
    sdp,
    type: 'video-offer'
  })
}
```    

sdp 内容是一个字符串，这个字符串应该是用 `\r\n` 分开的多行内容，看不大懂。    

接收的对等方在收到 offer 后的话，要做两件事，第一个就是创建自己的 `RTCPeerConnection`，然后添加 track。
第二个就是处理收到的 offer，并发送自己的 answer。    

```js
handleReceiveOffer = (offer) => {
    let localStream: MediaStream;
    console.log('组件收到 offer', offer);
    this.createPeerConnenction();
    let desc = new RTCSessionDescription(offer.sdp);
    this.connection?.setRemoteDescription(desc)
        .then(() => {
            return navigator.mediaDevices.getUserMedia({video: true, audio: true})
                .then(stream => {
                    localStream = stream;
                    if (this.videoRef.current) {
                        this.videoRef.current.srcObject = localStream;
                        this.videoRef.current.play();
                        this.setState({
                            playing: true,
                        });
                    }

                    localStream.getTracks().forEach(track => this.connection?.addTrack(track, localStream));
                })
                .then(() => {
                    return this.connection?.createAnswer();
                })
                .then(answer => {
                    return this.connection?.setLocalDescription(answer);
                })
                .then(() => {
                    this.props.onSendAnswer(offer.from, this.connection?.localDescription);
                })
                .catch((e) => {
                    console.log('send answer error', e);
                })
        })
}
```   

所以上面的这些代码，到底是应该称为做了什么呢。     

ICE 协商过程需要双方重复地发送 candidate 给对方，直到其将所有其支持的 RTCPeerConnection 媒体传输方式都
尝试过后。由于 ICE 并不清楚我们的信令服务器，所以我们需要在 icecandidate 事件中处理 candidate 的传输    


```ts
handleICECandidate = (event) => {
    if (event.candidate) {
        this.props.onSendCandidate({
            type: 'new-ice-candidate',
            to: this.state.connectId,
            candidate: event.candidate,
        })
    }
}

handleReceiveCandidate(candidate) {
    let candi = new RTCIceCandidate(candidate.candidate);
    this.connection?.addIceCandidate(candi)
        .catch(e => console.log('add candidate error', e));
}
```     

当流对话时有变动时，可能会重新触发 negotiationneeded 事件，然后整个流程重新执行一次，这种场景
包括这些情况：   

- 网络状态变动，比如说 WIFI 和 4G 的相互转换
- 前后置摄像头切换
- 流配置变动，比如说分辨率或者帧率     

